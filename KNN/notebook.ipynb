{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Reccomendation Algorithm\n",
    "\n",
    "I decided to use the PyNNDescent, which is based on the NN Descent algorithm. I decided to use an approximate nearest neighbors instead of true KNN as I calculated the time to find the predictions on the full data set to be around 2.5 hours. This wasn't feasable as lots of iterations needed to be ran. I used NN Descent as it is a scalable algorithm with relatively low overhead, and had a highly recommended python library to go along with it. I would have used HNSW, however the memory overhead had me worried as memory consumption was already a significant bottleneck.\n",
    "\n",
    "With NN Descent the total time to fit and predict on the full dataset is about 10 minutes, which is much more managable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from math import ceil, floor, sqrt\n",
    "from average import AverageRating\n",
    "from tqdm import tqdm\n",
    "from pynndescent.pynndescent_ import PyNNDescentTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sample):\n",
    "    folder_path = \"D:\\\\Users\\\\aidan\\\\MSOE\\\\grad\\\\RecommendationSystems\\\\movie-lens\"\n",
    "    ratings_path = folder_path + \"\\\\ratings.csv\"\n",
    "\n",
    "    if sample:\n",
    "        ratings_path = \"D:\\\\Users\\\\aidan\\\\MSOE\\\\grad\\\\RecommendationSystems\\\\KNN\\\\sampe_data.csv\"\n",
    "        pass\n",
    "    ratings = pd.read_csv(ratings_path)\n",
    "    if not sample:\n",
    "        original_movie_ids = set(ratings['movieId'])\n",
    "        movie_id_map = {original: new for new, original in enumerate(original_movie_ids)}\n",
    "        ratings['movieId'] = ratings['movieId'].map(movie_id_map)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = load_data(sample=False)\n",
    "data = csr_matrix((ratings['rating'], (ratings['userId'], ratings['movieId'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162542, 59047)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRating:\n",
    "    def __init__(self, k, metric: str):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.neighbors = PyNNDescentTransformer(n_neighbors=self.k, metric=self.metric)\n",
    "        self.training_ratings = None\n",
    "\n",
    "\n",
    "    def fit(self, training_ratings):\n",
    "        max_k = training_ratings.shape[0]\n",
    "        if self.k > max_k:\n",
    "            print(f\"k({self.k}) is greater than total samples, changing k to the number of samples({max_k})\")\n",
    "            self.k = max_k\n",
    "        self.neighbors = PyNNDescentTransformer(n_neighbors=self.k, metric=self.metric)\n",
    "        self.neighbors.fit(training_ratings)\n",
    "        self.training_ratings = training_ratings\n",
    "        \n",
    "\n",
    "    def predict(self, user_ratings):\n",
    "        if self.training_ratings is None:\n",
    "            raise Exception(\"Must fit before predicting\")\n",
    "        distances = self.neighbors.transform(user_ratings)\n",
    "        all_distances = distances.nonzero()[1]\n",
    "        neighbor_indices = np.array_split(all_distances, ceil(all_distances.shape[0]/self.k))\n",
    "        averageRating = AverageRating()\n",
    "        predictions = list()\n",
    "        for item in neighbor_indices:\n",
    "            averageRating.fit(self.training_ratings[item])\n",
    "            predictions.append(averageRating.predictions)\n",
    "        return vstack(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep:\n",
    "    \"\"\"\n",
    "    Class for splitting data and applying idf transformation.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, train_size=0.8, idf=False, norm=None):\n",
    "        self.raw_data = data\n",
    "        self.train_size = train_size\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.seen = None\n",
    "        self.unseen = None\n",
    "        if idf:\n",
    "            idf_transformer = TfidfTransformer(norm=norm, use_idf=True)\n",
    "            self.raw_data = idf_transformer.fit_transform(self.raw_data)\n",
    "\n",
    "    def split(self):\n",
    "        \"\"\"\n",
    "        Splits data into train and test. Also splits test data into seen and unseen groups.\n",
    "        \"\"\"\n",
    "        self.train, self.test = DataPrep.train_test_split(self.raw_data, train_size=self.train_size)\n",
    "        self.seen, self.unseen = DataPrep.user_split(self.test)\n",
    "        return self.train, self.seen, self.unseen\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_test_split(data, train_size):\n",
    "        train, test = sklearn_train_test_split(data, train_size=train_size)\n",
    "        return train, test\n",
    "\n",
    "    @staticmethod\n",
    "    def user_split(user_item_matrix: csr_matrix, split=0.8):\n",
    "        seen_data = np.array([])\n",
    "        seen_indices = np.array([])\n",
    "        seen_indptr = np.array([0])\n",
    "\n",
    "        unseen_data = np.array([])\n",
    "        unseen_indices = np.array([])\n",
    "        unseen_indptr = np.array([0])\n",
    "\n",
    "        for i in range(len(user_item_matrix.indptr.copy()) - 1):\n",
    "            row_start = user_item_matrix.indptr[i]\n",
    "            row_end   = user_item_matrix.indptr[i+1] \n",
    "            sample_size = floor((row_end - row_start) * split)\n",
    "            if sample_size == 0: #ensures something is in the test data\n",
    "                sample_size += 1\n",
    "\n",
    "            row_indices = user_item_matrix.indices[row_start: row_end]\n",
    "            row_data = user_item_matrix.data[row_start: row_end]\n",
    "\n",
    "\n",
    "            data_idx = np.arange(len(row_data))\n",
    "            seen_idx = np.random.choice(data_idx, size=sample_size, replace=False)\n",
    "            unseen_idx = np.setdiff1d(data_idx, seen_idx)\n",
    "            \n",
    "            #appending data to matrices\n",
    "            seen_data = np.append(seen_data, row_data[seen_idx])\n",
    "            unseen_data = np.append(unseen_data, row_data[unseen_idx])\n",
    "\n",
    "            #appending indices\n",
    "            seen_indices = np.append(seen_indices, row_indices[seen_idx])\n",
    "            unseen_indices = np.append(unseen_indices, row_indices[unseen_idx])\n",
    "\n",
    "            seen_indptr = np.append(seen_indptr, [seen_indptr[-1] + len(seen_idx)])\n",
    "            unseen_indptr = np.append(unseen_indptr, [unseen_indptr[-1] + len(unseen_idx)])\n",
    "        return csr_matrix((seen_data, seen_indices, seen_indptr), dtype=np.float32), csr_matrix((unseen_data, unseen_indices, unseen_indptr),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(train, seen, unseen, k, metric,batch_size):\n",
    "    model = KNNRating(k=k, metric=metric)\n",
    "    model.fit(train)\n",
    "\n",
    "    batched_input = list()\n",
    "    if batch_size > seen.shape[0]:\n",
    "        batched_input.append(seen)\n",
    "    else:\n",
    "        for i in range(0, seen.shape[0], batch_size):\n",
    "            batched_input.append(seen[i:i+batch_size])\n",
    "    predictions = list()\n",
    "    for batch in tqdm(batched_input):\n",
    "        predictions.append(model.predict(batch))\n",
    "    y_pred = vstack(predictions)\n",
    "    return y_pred, unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(predicted, true, rmse=True, pearson=True, sparsity=True, set_diff=True, debug=True):\n",
    "    nonzeros = true.nonzero()\n",
    "    y_true = np.array(true[nonzeros], dtype=np.float32)[0]\n",
    "    y_pred = np.array(predicted[nonzeros], dtype=np.float32)[0]\n",
    "    outputs = dict()\n",
    "    if rmse:\n",
    "        rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "        outputs['rmse'] = rmse\n",
    "        if debug:\n",
    "            print(f\"rmse: {rmse}\")\n",
    "    if pearson:\n",
    "        r_squared = pearsonr(y_true, y_pred)[1] ** 2\n",
    "        outputs['r_squared'] = r_squared\n",
    "        if debug:\n",
    "            print(f\"r2 score: {r_squared}\")\n",
    "    if set_diff:\n",
    "        #batching set diff\n",
    "        batch_size=400\n",
    "        pred_batched = list()\n",
    "        true_batched = list()\n",
    "        for i in range(0, true.shape[0], batch_size):\n",
    "            pred_batched.append(predicted[i:i+batch_size])\n",
    "            true_batched.append(true[i:i+batch_size])\n",
    "        pair_in_both = 0\n",
    "        pair_in_true = 0\n",
    "        for pred_batch, true_batch in tqdm(zip(pred_batched, true_batched)):\n",
    "            pred_users, pred_movies = pred_batch.nonzero()\n",
    "            pred_pairs = set(zip(pred_users,pred_movies))\n",
    "            true_users, true_movies = true_batch.nonzero()\n",
    "            true_pairs = set(zip(true_users, true_movies))\n",
    "\n",
    "            pair_in_both += len(true_pairs.intersection(pred_pairs))\n",
    "            pair_in_true += len(true_pairs)\n",
    "\n",
    "        non_zero_ratings = pair_in_both / pair_in_true\n",
    "        outputs['non_zero_ratings'] = non_zero_ratings\n",
    "        if debug:\n",
    "            print(f\"Fraction of user-movie pairs with non-zero predicted ratings: {non_zero_ratings}\")\n",
    "    if sparsity:\n",
    "        sparsity = predicted.getnnz() / (predicted.shape[0] * predicted.shape[1])\n",
    "        outputs['sparsity'] = predicted.getnnz() / (predicted.shape[0] * predicted.shape[1])\n",
    "        if debug:\n",
    "            print(f\"Sparsity: {sparsity}\")\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = DataPrep(data, idf=False)\n",
    "train, seen, unseen = prep.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets():\n",
    "    norms = [None, 'l2']\n",
    "    idfs = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train, seen, unseen, idf, norm, batch_size=100):\n",
    "    ks = [5,10,25,50,100]\n",
    "    metrics = ['euclidean','cosine']\n",
    "\n",
    "    for k in ks:\n",
    "        for metric in metrics:\n",
    "            y_pred, y_true = batch_predict(train, seen, unseen, k=k, metric=metric, batch_size=batch_size)\n",
    "            output = score(y_pred, y_true, set_diff=False, debug=False)\n",
    "            output_str = f\"k: {k}, metric: {metric}, idf: {idf}, norm: {norm}\\n\\trmse: {output['rmse']}\\n\\tr^2: {output['r_squared']}\\n\\tsparsity: {output['sparsity']}\\n\"\n",
    "            with open(\"output.txt\", \"a\") as f:\n",
    "                f.write(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/326 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 36.3 GiB for an array with shape (82591, 2, 59047) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43munseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43midf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(train, seen, unseen, idf, norm, batch_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ks:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m----> 7\u001b[0m         y_pred, y_true \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         output \u001b[38;5;241m=\u001b[39m score(y_pred, y_true, set_diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m         output_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, idf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, norm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mrmse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mr^2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_squared\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124msparsity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mbatch_predict\u001b[1;34m(train, seen, unseen, k, metric, batch_size)\u001b[0m\n\u001b[0;32m     11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(batched_input):\n\u001b[1;32m---> 13\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m vstack(predictions)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, unseen\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mKNNRating.predict\u001b[1;34m(self, user_ratings)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_ratings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust fit before predicting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ratings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m all_distances \u001b[38;5;241m=\u001b[39m distances\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     24\u001b[0m neighbor_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(all_distances, ceil(all_distances\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pynndescent\\pynndescent_.py:2170\u001b[0m, in \u001b[0;36mPyNNDescentTransformer.transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   2168\u001b[0m     indices, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_\u001b[38;5;241m.\u001b[39mneighbor_graph\n\u001b[0;32m   2169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2170\u001b[0m     indices, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_epsilon\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m   2175\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ts(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstructing neighbor matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pynndescent\\pynndescent_.py:1689\u001b[0m, in \u001b[0;36mNNDescent.query\u001b[1;34m(self, query_data, k, epsilon)\u001b[0m\n\u001b[0;32m   1658\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query the training graph_data for the k nearest neighbors\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m \n\u001b[0;32m   1660\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m    training graph_data.\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_search_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1689\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_search_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_sparse:\n\u001b[0;32m   1692\u001b[0m     \u001b[38;5;66;03m# Standard case\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_search_function\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pynndescent\\pynndescent_.py:1025\u001b[0m, in \u001b[0;36mNNDescent._init_search_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         best_trees \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rp_forest[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m best_tree_indices]\n\u001b[0;32m   1024\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rp_forest\n\u001b[1;32m-> 1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_forest \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert_tree_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbest_trees\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1032\u001b[0m nnz_pre_diversify \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neighbor_graph[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_sparse:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pynndescent\\pynndescent_.py:1026\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         best_trees \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rp_forest[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m best_tree_indices]\n\u001b[0;32m   1024\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rp_forest\n\u001b[0;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_forest \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1026\u001b[0m             \u001b[43mconvert_tree_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m best_trees\n\u001b[0;32m   1030\u001b[0m         ]\n\u001b[0;32m   1032\u001b[0m nnz_pre_diversify \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neighbor_graph[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_sparse:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pynndescent\\rp_trees.py:1238\u001b[0m, in \u001b[0;36mconvert_tree_format\u001b[1;34m(tree, data_size, data_dim)\u001b[0m\n\u001b[0;32m   1236\u001b[0m     is_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m     hyperplane_dim \u001b[38;5;241m=\u001b[39m data_dim\n\u001b[1;32m-> 1238\u001b[0m     hyperplanes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperplane_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m     hyperplanes[:, \u001b[38;5;241m0\u001b[39m, :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1241\u001b[0m offsets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_nodes, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 36.3 GiB for an array with shape (82591, 2, 59047) and data type float32"
     ]
    }
   ],
   "source": [
    "grid_search(train,seen,unseen,idf=False,norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<130033x59047 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20076478 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "#y_pred, y_true = batch_predict(train, seen, unseen, k=4, metric='euclidean', batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.795054898817152\n",
      "r2 score: 1.0\n",
      "Sparsity: 1.0\n"
     ]
    }
   ],
   "source": [
    "#score_output = score(y_pred, y_true, set_diff=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Results\n",
    "\n",
    "|Parameter Input| RMSE| $r^2$| Sparsity|\n",
    "|--------------|------|------|---------|\n",
    "|10, E, IDF, l2|0.0587|-0.281|0.0134|\n",
    "|10, C, IDF, l2|0.0542|-0.167|0.0123|\n",
    "|50, E, IDF, l2||||"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
